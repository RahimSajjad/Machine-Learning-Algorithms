{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version of the Library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python :3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]\n",
      "Scipy :1.5.2\n",
      "Numpy :1.19.1\n",
      "Matplotlib :3.3.1\n",
      "Pandas :1.1.4\n",
      "Sklearn :1.1.4\n",
      "Flask :1.1.2\n",
      "conda :4.9.2\n"
     ]
    }
   ],
   "source": [
    "#python version\n",
    "import sys\n",
    "print('Python :{}'.format(sys.version))\n",
    "\n",
    "#scipy\n",
    "import scipy\n",
    "print('Scipy :{}'.format(scipy.__version__))\n",
    "\n",
    "#Numpy\n",
    "import numpy\n",
    "print('Numpy :{}'.format(numpy.__version__))\n",
    "\n",
    "#Matplotlib\n",
    "import matplotlib\n",
    "print('Matplotlib :{}'.format(matplotlib.__version__))\n",
    "\n",
    "#Pandas\n",
    "import pandas\n",
    "print('Pandas :{}'.format(pandas.__version__))\n",
    "\n",
    "#Sklearn\n",
    "import sklearn\n",
    "print('Sklearn :{}'.format(pandas.__version__))\n",
    "\n",
    "#Flask\n",
    "import flask\n",
    "print('Flask :{}'.format(flask.__version__))\n",
    "\n",
    "import conda\n",
    "print('conda :{}'.format(conda.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading all the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data: as csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes = pd.read_csv(\"Recipes.csv\")\n",
    "defects = pd.read_csv(\"Defects.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HEAT_ID</th>\n",
       "      <th>Material_Code</th>\n",
       "      <th>NAME</th>\n",
       "      <th>WEIGHT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1701190</td>\n",
       "      <td>112</td>\n",
       "      <td># 2 HEAVY MELT</td>\n",
       "      <td>158758.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1701192</td>\n",
       "      <td>113</td>\n",
       "      <td>PIG IRON</td>\n",
       "      <td>50306.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1701192</td>\n",
       "      <td>115</td>\n",
       "      <td>HOME SCRAP</td>\n",
       "      <td>2215.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HEAT_ID  Material_Code            NAME    WEIGHT\n",
       "0  1701190            112  # 2 HEAVY MELT  158758.0\n",
       "1  1701192            113        PIG IRON   50306.6\n",
       "2  1701192            115      HOME SCRAP    2215.8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HEAT_ID</th>\n",
       "      <th>Material_Code</th>\n",
       "      <th>WEIGHT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000020e+05</td>\n",
       "      <td>100002.000000</td>\n",
       "      <td>100002.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.749167e+06</td>\n",
       "      <td>129.451171</td>\n",
       "      <td>19169.098051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.765453e+04</td>\n",
       "      <td>24.834632</td>\n",
       "      <td>17224.494762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.701190e+06</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.707906e+06</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>4822.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.715312e+06</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>10813.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.804858e+06</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>30399.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.811206e+06</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>158758.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            HEAT_ID  Material_Code         WEIGHT\n",
       "count  1.000020e+05  100002.000000  100002.000000\n",
       "mean   1.749167e+06     129.451171   19169.098051\n",
       "std    4.765453e+04      24.834632   17224.494762\n",
       "min    1.701190e+06     112.000000       0.500000\n",
       "25%    1.707906e+06     115.000000    4822.100000\n",
       "50%    1.715312e+06     120.000000   10813.900000\n",
       "75%    1.804858e+06     126.000000   30399.675000\n",
       "max    1.811206e+06     215.000000  158758.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PIECE_ID</th>\n",
       "      <th>HEAT_ID</th>\n",
       "      <th>DEFECT_TYPE</th>\n",
       "      <th>DEFECT_NAME</th>\n",
       "      <th>DEFECT_GROUP_ID</th>\n",
       "      <th>DEFECT_GROUP_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167872</td>\n",
       "      <td>1701192</td>\n",
       "      <td>59</td>\n",
       "      <td>Scabs</td>\n",
       "      <td>SU</td>\n",
       "      <td>1-Surface</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>167867</td>\n",
       "      <td>1701192</td>\n",
       "      <td>59</td>\n",
       "      <td>Scabs</td>\n",
       "      <td>SU</td>\n",
       "      <td>1-Surface</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>167869</td>\n",
       "      <td>1701192</td>\n",
       "      <td>63</td>\n",
       "      <td>Scratches</td>\n",
       "      <td>SU</td>\n",
       "      <td>1-Surface</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PIECE_ID  HEAT_ID  DEFECT_TYPE DEFECT_NAME DEFECT_GROUP_ID  \\\n",
       "0    167872  1701192           59       Scabs              SU   \n",
       "1    167867  1701192           59       Scabs              SU   \n",
       "2    167869  1701192           63   Scratches              SU   \n",
       "\n",
       "  DEFECT_GROUP_Name  \n",
       "0         1-Surface  \n",
       "1         1-Surface  \n",
       "2         1-Surface  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defects.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PIECE_ID</th>\n",
       "      <th>HEAT_ID</th>\n",
       "      <th>DEFECT_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>563048.000000</td>\n",
       "      <td>5.630480e+05</td>\n",
       "      <td>563048.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>298638.715351</td>\n",
       "      <td>1.744834e+06</td>\n",
       "      <td>175.309350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>83246.354402</td>\n",
       "      <td>4.680686e+04</td>\n",
       "      <td>33.533375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>166934.000000</td>\n",
       "      <td>1.701192e+06</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>224145.000000</td>\n",
       "      <td>1.706120e+06</td>\n",
       "      <td>167.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>299206.000000</td>\n",
       "      <td>1.714372e+06</td>\n",
       "      <td>182.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>358950.250000</td>\n",
       "      <td>1.802874e+06</td>\n",
       "      <td>190.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>679818.000000</td>\n",
       "      <td>1.811206e+06</td>\n",
       "      <td>238.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            PIECE_ID       HEAT_ID    DEFECT_TYPE\n",
       "count  563048.000000  5.630480e+05  563048.000000\n",
       "mean   298638.715351  1.744834e+06     175.309350\n",
       "std     83246.354402  4.680686e+04      33.533375\n",
       "min    166934.000000  1.701192e+06      36.000000\n",
       "25%    224145.000000  1.706120e+06     167.000000\n",
       "50%    299206.000000  1.714372e+06     182.000000\n",
       "75%    358950.250000  1.802874e+06     190.000000\n",
       "max    679818.000000  1.811206e+06     238.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defects.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data profiling using Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas_profiling as pp\n",
    "#pp.ProfileReport(recipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas_profiling as pp\n",
    "#pp.ProfileReport(defects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defects.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipes data: \n",
      "\n",
      "   HEAT_ID  Material_Code            NAME    WEIGHT\n",
      "0  1701190            112  # 2 HEAVY MELT  158758.0\n",
      "1  1701192            113        PIG IRON   50306.6\n",
      "----------------------------------------------------------------------\n",
      "Defects data:\n",
      "\n",
      "   PIECE_ID  HEAT_ID  DEFECT_TYPE DEFECT_NAME DEFECT_GROUP_ID  \\\n",
      "0    167872  1701192           59       Scabs              SU   \n",
      "1    167867  1701192           59       Scabs              SU   \n",
      "\n",
      "  DEFECT_GROUP_Name  \n",
      "0         1-Surface  \n",
      "1         1-Surface  \n"
     ]
    }
   ],
   "source": [
    "print(f\"Recipes data: \\n\")\n",
    "print(recipes.head(2))\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "print(f\"Defects data:\\n\")\n",
    "print(defects.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing or Data Cleaning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### data Info & Unique value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique HEAT_ID of Recipes: [112 113 115 114 117 119 121 126 124 120 116 180 166 183 182 190 181 122\n",
      " 125 118 208 209 207 210 211 215 212 214 213]\n",
      "\n",
      "Unique HEAT_ID of Recipes: [1701190 1701192 1701194 ... 1811202 1811204 1811206]\n",
      "------------------------------------------------------------------------------------\n",
      "Unique DEFECT_TYPE of defects: [ 59  63  71  89  90 146 148 149 150 167 168 169 182 190 151 157 147 197\n",
      " 134 153 155 154 156 211 193  56  46  87  49  60  52 212 105 186 130 118\n",
      " 104 125  96 173 165  88 103 114 175 176 100  99  41  66 126 191 192  91\n",
      "  55 184  53 121  79 204 187 185 194 107  94 102  47 214  86  68 101 198\n",
      "  43  80 183 174 110 119  61 188  74 120 109  92 170 133  54  95 111  62\n",
      "  78 108 113  37  65  39 213  73  44 128 201 115  98 208  75  97  69  81\n",
      " 202 135  38 152 207 199  77 136 216 196  36 205 117  72  82  93  45  76\n",
      "  42 164  64 210 129 127  57 200 116  83 222 162 223 195 171 122 206 158\n",
      "  58 178 177 172  48  50 209 215 106  67  51  40 238 217 112 159 160  84]\n",
      "Unique DEFECT_Group_Id of defects: ['SU' 'SH' 'DM' 'OTH' 'MET' 'CCTO' 'IDF' 'PR' 'PK' 'EQ']\n",
      "29\n",
      "162\n"
     ]
    }
   ],
   "source": [
    "#uniq name from data\n",
    "print(f\"Unique HEAT_ID of Recipes: {recipes['Material_Code'].unique()}\\n\")\n",
    "print(f\"Unique HEAT_ID of Recipes: {recipes['HEAT_ID'].unique()}\")\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(f\"Unique DEFECT_TYPE of defects: {defects['DEFECT_TYPE'].unique()}\")\n",
    "print(f\"Unique DEFECT_Group_Id of defects: {defects['DEFECT_GROUP_ID'].unique()}\")\n",
    "\n",
    "print(len(recipes['Material_Code'].unique()))\n",
    "\n",
    "print(len(defects['DEFECT_TYPE'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Recipes data: 100002 and Shape of the data (100002, 4)\n",
      "Length of Defects data: 563048 and Shape of the data (563048, 6)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of Recipes data: {len(recipes)} and Shape of the data {recipes.shape}\")\n",
    "print(f\"Length of Defects data: {len(defects)} and Shape of the data {defects.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Columns name of Recipes: ['HEAT_ID', 'Material_Code', 'NAME', 'WEIGHT']\n",
      "All Columns name of Defects: ['PIECE_ID', 'HEAT_ID', 'DEFECT_TYPE', 'DEFECT_NAME', 'DEFECT_GROUP_ID', 'DEFECT_GROUP_Name']\n"
     ]
    }
   ],
   "source": [
    "print(f\"All Columns name of Recipes: {list(recipes.columns)}\")\n",
    "print(f\"All Columns name of Defects: {list(defects.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Pivot table for 'recipes.csv' file base on 'HEAT_ID'\n",
    "df = pd.pivot_table(recipes, index=\"HEAT_ID\", columns=['Material_Code'], values='WEIGHT')\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Material_Code</th>\n",
       "      <th>HEAT_ID</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1701190</td>\n",
       "      <td>158758.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1701192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50306.6</td>\n",
       "      <td>3473.6</td>\n",
       "      <td>2215.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Material_Code  HEAT_ID       112      113     114     115  116  117  118  119  \\\n",
       "0              1701190  158758.0      NaN     NaN     NaN  NaN  NaN  NaN  NaN   \n",
       "1              1701192       NaN  50306.6  3473.6  2215.8  NaN  NaN  NaN  NaN   \n",
       "\n",
       "Material_Code  120  ...  190  207  208  209  210  211  212  213  214  215  \n",
       "0              NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1              NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Add New Columns:Num,Sum,Mean,Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Sum Columns\n",
    "df[\"Num\"]=df.iloc[:,1:30].count(axis=1)\n",
    "df['Sum'] = df.iloc[:, 1:30].sum(axis=1)\n",
    "df['Mean'] = df.iloc[:, 1:30].mean(axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Material_Code</th>\n",
       "      <th>HEAT_ID</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>...</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>Num</th>\n",
       "      <th>Sum</th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1701190</td>\n",
       "      <td>158758.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>158758.0</td>\n",
       "      <td>158758.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1701192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50306.6</td>\n",
       "      <td>3473.6</td>\n",
       "      <td>2215.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>55996.0</td>\n",
       "      <td>18665.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1701194</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49903.8</td>\n",
       "      <td>3426.0</td>\n",
       "      <td>2322.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34129.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4545.9</td>\n",
       "      <td>2180.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>160919.8</td>\n",
       "      <td>17879.977778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1701196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49893.9</td>\n",
       "      <td>3173.8</td>\n",
       "      <td>1812.6</td>\n",
       "      <td>3173.8</td>\n",
       "      <td>35378.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4533.7</td>\n",
       "      <td>1812.6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>139237.8</td>\n",
       "      <td>13923.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1701198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22624.8</td>\n",
       "      <td>1544.9</td>\n",
       "      <td>1046.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15114.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2066.6</td>\n",
       "      <td>1106.8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>50799.3</td>\n",
       "      <td>6349.912500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12741</th>\n",
       "      <td>1811198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31282.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50207.3</td>\n",
       "      <td>6172.5</td>\n",
       "      <td>6422.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8431.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>151817.6</td>\n",
       "      <td>16868.622222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12742</th>\n",
       "      <td>1811200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32899.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50506.7</td>\n",
       "      <td>7185.4</td>\n",
       "      <td>6217.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7839.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>152339.2</td>\n",
       "      <td>16926.577778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12743</th>\n",
       "      <td>1811202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31732.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51175.3</td>\n",
       "      <td>6381.1</td>\n",
       "      <td>6274.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8656.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>152226.8</td>\n",
       "      <td>16914.088889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12744</th>\n",
       "      <td>1811204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32145.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51277.3</td>\n",
       "      <td>6783.5</td>\n",
       "      <td>7053.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8866.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>152497.8</td>\n",
       "      <td>16944.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12745</th>\n",
       "      <td>1811206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32147.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51038.7</td>\n",
       "      <td>6841.5</td>\n",
       "      <td>6534.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8785.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>152180.4</td>\n",
       "      <td>16908.933333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12746 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Material_Code  HEAT_ID       112      113     114     115     116      117  \\\n",
       "0              1701190  158758.0      NaN     NaN     NaN     NaN      NaN   \n",
       "1              1701192       NaN  50306.6  3473.6  2215.8     NaN      NaN   \n",
       "2              1701194       NaN  49903.8  3426.0  2322.8     NaN  34129.7   \n",
       "3              1701196       NaN  49893.9  3173.8  1812.6  3173.8  35378.9   \n",
       "4              1701198       NaN  22624.8  1544.9  1046.0     NaN  15114.6   \n",
       "...                ...       ...      ...     ...     ...     ...      ...   \n",
       "12741          1811198       NaN  31282.9     NaN     NaN     NaN  50207.3   \n",
       "12742          1811200       NaN  32899.5     NaN     NaN     NaN  50506.7   \n",
       "12743          1811202       NaN  31732.0     NaN     NaN     NaN  51175.3   \n",
       "12744          1811204       NaN  32145.2     NaN     NaN     NaN  51277.3   \n",
       "12745          1811206       NaN  32147.5     NaN     NaN     NaN  51038.7   \n",
       "\n",
       "Material_Code     118     119     120  ...  209  210  211  212     213  214  \\\n",
       "0                 NaN     NaN     NaN  ...  NaN  NaN  NaN  NaN     NaN  NaN   \n",
       "1                 NaN     NaN     NaN  ...  NaN  NaN  NaN  NaN     NaN  NaN   \n",
       "2                 NaN  4545.9  2180.0  ...  NaN  NaN  NaN  NaN     NaN  NaN   \n",
       "3                 NaN  4533.7  1812.6  ...  NaN  NaN  NaN  NaN     NaN  NaN   \n",
       "4                 NaN  2066.6  1106.8  ...  NaN  NaN  NaN  NaN     NaN  NaN   \n",
       "...               ...     ...     ...  ...  ...  ...  ...  ...     ...  ...   \n",
       "12741          6172.5  6422.9     NaN  ...  NaN  NaN  NaN  NaN  8431.4  NaN   \n",
       "12742          7185.4  6217.4     NaN  ...  NaN  NaN  NaN  NaN  7839.4  NaN   \n",
       "12743          6381.1  6274.6     NaN  ...  NaN  NaN  NaN  NaN  8656.4  NaN   \n",
       "12744          6783.5  7053.8     NaN  ...  NaN  NaN  NaN  NaN  8866.8  NaN   \n",
       "12745          6841.5  6534.9     NaN  ...  NaN  NaN  NaN  NaN  8785.2  NaN   \n",
       "\n",
       "Material_Code  215  Num       Sum           Mean  \n",
       "0              NaN    1  158758.0  158758.000000  \n",
       "1              NaN    3   55996.0   18665.333333  \n",
       "2              NaN    9  160919.8   17879.977778  \n",
       "3              NaN   10  139237.8   13923.780000  \n",
       "4              NaN    8   50799.3    6349.912500  \n",
       "...            ...  ...       ...            ...  \n",
       "12741          NaN    9  151817.6   16868.622222  \n",
       "12742          NaN    9  152339.2   16926.577778  \n",
       "12743          NaN    9  152226.8   16914.088889  \n",
       "12744          NaN    9  152497.8   16944.200000  \n",
       "12745          NaN    9  152180.4   16908.933333  \n",
       "\n",
       "[12746 rows x 33 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Recipies the data: (12746, 33)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of Recipies the data: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge Data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(419277, 38)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Marge recipes data with defect data,Fill with 0, Drop the duplicates values\n",
    "df = pd.merge(defects, df, on = 'HEAT_ID')\n",
    "df = df.fillna(0)\n",
    "\n",
    "#Drop Duplicates\n",
    "df=df.drop_duplicates()\n",
    "\n",
    "#Drop duplicate columns\n",
    "df = df.loc[:,~df.columns.duplicated()]\n",
    "df\n",
    "\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PIECE_ID</th>\n",
       "      <th>HEAT_ID</th>\n",
       "      <th>DEFECT_TYPE</th>\n",
       "      <th>DEFECT_NAME</th>\n",
       "      <th>DEFECT_GROUP_ID</th>\n",
       "      <th>DEFECT_GROUP_Name</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>...</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>Num</th>\n",
       "      <th>Sum</th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167872</td>\n",
       "      <td>1701192</td>\n",
       "      <td>59</td>\n",
       "      <td>Scabs</td>\n",
       "      <td>SU</td>\n",
       "      <td>1-Surface</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50306.6</td>\n",
       "      <td>3473.6</td>\n",
       "      <td>2215.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>55996.0</td>\n",
       "      <td>18665.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>167867</td>\n",
       "      <td>1701192</td>\n",
       "      <td>59</td>\n",
       "      <td>Scabs</td>\n",
       "      <td>SU</td>\n",
       "      <td>1-Surface</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50306.6</td>\n",
       "      <td>3473.6</td>\n",
       "      <td>2215.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>55996.0</td>\n",
       "      <td>18665.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>167869</td>\n",
       "      <td>1701192</td>\n",
       "      <td>63</td>\n",
       "      <td>Scratches</td>\n",
       "      <td>SU</td>\n",
       "      <td>1-Surface</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50306.6</td>\n",
       "      <td>3473.6</td>\n",
       "      <td>2215.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>55996.0</td>\n",
       "      <td>18665.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>167871</td>\n",
       "      <td>1701192</td>\n",
       "      <td>71</td>\n",
       "      <td>Stain</td>\n",
       "      <td>SU</td>\n",
       "      <td>1-Surface</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50306.6</td>\n",
       "      <td>3473.6</td>\n",
       "      <td>2215.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>55996.0</td>\n",
       "      <td>18665.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PIECE_ID  HEAT_ID  DEFECT_TYPE DEFECT_NAME DEFECT_GROUP_ID  \\\n",
       "0    167872  1701192           59       Scabs              SU   \n",
       "1    167867  1701192           59       Scabs              SU   \n",
       "2    167869  1701192           63   Scratches              SU   \n",
       "3    167871  1701192           71       Stain              SU   \n",
       "\n",
       "  DEFECT_GROUP_Name  112      113     114     115  ...  209  210  211  212  \\\n",
       "0         1-Surface  0.0  50306.6  3473.6  2215.8  ...  0.0  0.0  0.0  0.0   \n",
       "1         1-Surface  0.0  50306.6  3473.6  2215.8  ...  0.0  0.0  0.0  0.0   \n",
       "2         1-Surface  0.0  50306.6  3473.6  2215.8  ...  0.0  0.0  0.0  0.0   \n",
       "3         1-Surface  0.0  50306.6  3473.6  2215.8  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   213  214  215  Num      Sum          Mean  \n",
       "0  0.0  0.0  0.0    3  55996.0  18665.333333  \n",
       "1  0.0  0.0  0.0    3  55996.0  18665.333333  \n",
       "2  0.0  0.0  0.0    3  55996.0  18665.333333  \n",
       "3  0.0  0.0  0.0    3  55996.0  18665.333333  \n",
       "\n",
       "[4 rows x 38 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting/Describing Data\n",
    "#df.sort_values(['DEFECT_TYPE', 'DEFECT_GROUP_ID'], ascending=[0,1])\n",
    "#df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the Null Value\n",
    "#df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Repeat Columns\n",
    "\n",
    "df['Repeat']=df.groupby('HEAT_ID').HEAT_ID.transform('count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PIECE_ID</th>\n",
       "      <th>HEAT_ID</th>\n",
       "      <th>DEFECT_TYPE</th>\n",
       "      <th>DEFECT_NAME</th>\n",
       "      <th>DEFECT_GROUP_ID</th>\n",
       "      <th>DEFECT_GROUP_Name</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>...</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>Num</th>\n",
       "      <th>Sum</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Repeat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167872</td>\n",
       "      <td>1701192</td>\n",
       "      <td>59</td>\n",
       "      <td>Scabs</td>\n",
       "      <td>SU</td>\n",
       "      <td>1-Surface</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50306.6</td>\n",
       "      <td>3473.6</td>\n",
       "      <td>2215.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>55996.0</td>\n",
       "      <td>18665.333333</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>167867</td>\n",
       "      <td>1701192</td>\n",
       "      <td>59</td>\n",
       "      <td>Scabs</td>\n",
       "      <td>SU</td>\n",
       "      <td>1-Surface</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50306.6</td>\n",
       "      <td>3473.6</td>\n",
       "      <td>2215.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>55996.0</td>\n",
       "      <td>18665.333333</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>167869</td>\n",
       "      <td>1701192</td>\n",
       "      <td>63</td>\n",
       "      <td>Scratches</td>\n",
       "      <td>SU</td>\n",
       "      <td>1-Surface</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50306.6</td>\n",
       "      <td>3473.6</td>\n",
       "      <td>2215.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>55996.0</td>\n",
       "      <td>18665.333333</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>167871</td>\n",
       "      <td>1701192</td>\n",
       "      <td>71</td>\n",
       "      <td>Stain</td>\n",
       "      <td>SU</td>\n",
       "      <td>1-Surface</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50306.6</td>\n",
       "      <td>3473.6</td>\n",
       "      <td>2215.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>55996.0</td>\n",
       "      <td>18665.333333</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>167868</td>\n",
       "      <td>1701192</td>\n",
       "      <td>71</td>\n",
       "      <td>Stain</td>\n",
       "      <td>SU</td>\n",
       "      <td>1-Surface</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50306.6</td>\n",
       "      <td>3473.6</td>\n",
       "      <td>2215.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>55996.0</td>\n",
       "      <td>18665.333333</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511067</th>\n",
       "      <td>477203</td>\n",
       "      <td>1811206</td>\n",
       "      <td>182</td>\n",
       "      <td>pending PQA results</td>\n",
       "      <td>OTH</td>\n",
       "      <td>0-Other</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32147.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8785.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>152180.4</td>\n",
       "      <td>16908.933333</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511068</th>\n",
       "      <td>477203</td>\n",
       "      <td>1811206</td>\n",
       "      <td>212</td>\n",
       "      <td>Pending Test Results</td>\n",
       "      <td>OTH</td>\n",
       "      <td>0-Other</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32147.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8785.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>152180.4</td>\n",
       "      <td>16908.933333</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511069</th>\n",
       "      <td>477203</td>\n",
       "      <td>1811206</td>\n",
       "      <td>193</td>\n",
       "      <td>Length Questionable - Verify Length</td>\n",
       "      <td>DM</td>\n",
       "      <td>3-Dimension</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32147.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8785.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>152180.4</td>\n",
       "      <td>16908.933333</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511070</th>\n",
       "      <td>477203</td>\n",
       "      <td>1811206</td>\n",
       "      <td>190</td>\n",
       "      <td>Wait For Weight - No L2 Scale Weight</td>\n",
       "      <td>DM</td>\n",
       "      <td>3-Dimension</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32147.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8785.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>152180.4</td>\n",
       "      <td>16908.933333</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511071</th>\n",
       "      <td>477203</td>\n",
       "      <td>1811206</td>\n",
       "      <td>216</td>\n",
       "      <td>Bad Dimensions on Calculated Weight</td>\n",
       "      <td>OTH</td>\n",
       "      <td>0-Other</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32147.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8785.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>152180.4</td>\n",
       "      <td>16908.933333</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>419277 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PIECE_ID  HEAT_ID  DEFECT_TYPE                           DEFECT_NAME  \\\n",
       "0         167872  1701192           59                                 Scabs   \n",
       "1         167867  1701192           59                                 Scabs   \n",
       "2         167869  1701192           63                             Scratches   \n",
       "3         167871  1701192           71                                 Stain   \n",
       "4         167868  1701192           71                                 Stain   \n",
       "...          ...      ...          ...                                   ...   \n",
       "511067    477203  1811206          182                   pending PQA results   \n",
       "511068    477203  1811206          212                  Pending Test Results   \n",
       "511069    477203  1811206          193   Length Questionable - Verify Length   \n",
       "511070    477203  1811206          190  Wait For Weight - No L2 Scale Weight   \n",
       "511071    477203  1811206          216   Bad Dimensions on Calculated Weight   \n",
       "\n",
       "       DEFECT_GROUP_ID DEFECT_GROUP_Name  112      113     114     115  ...  \\\n",
       "0                   SU         1-Surface  0.0  50306.6  3473.6  2215.8  ...   \n",
       "1                   SU         1-Surface  0.0  50306.6  3473.6  2215.8  ...   \n",
       "2                   SU         1-Surface  0.0  50306.6  3473.6  2215.8  ...   \n",
       "3                   SU         1-Surface  0.0  50306.6  3473.6  2215.8  ...   \n",
       "4                   SU         1-Surface  0.0  50306.6  3473.6  2215.8  ...   \n",
       "...                ...               ...  ...      ...     ...     ...  ...   \n",
       "511067             OTH           0-Other  0.0  32147.5     0.0     0.0  ...   \n",
       "511068             OTH           0-Other  0.0  32147.5     0.0     0.0  ...   \n",
       "511069              DM       3-Dimension  0.0  32147.5     0.0     0.0  ...   \n",
       "511070              DM       3-Dimension  0.0  32147.5     0.0     0.0  ...   \n",
       "511071             OTH           0-Other  0.0  32147.5     0.0     0.0  ...   \n",
       "\n",
       "        210  211  212     213  214  215  Num       Sum          Mean  Repeat  \n",
       "0       0.0  0.0  0.0     0.0  0.0  0.0    3   55996.0  18665.333333      79  \n",
       "1       0.0  0.0  0.0     0.0  0.0  0.0    3   55996.0  18665.333333      79  \n",
       "2       0.0  0.0  0.0     0.0  0.0  0.0    3   55996.0  18665.333333      79  \n",
       "3       0.0  0.0  0.0     0.0  0.0  0.0    3   55996.0  18665.333333      79  \n",
       "4       0.0  0.0  0.0     0.0  0.0  0.0    3   55996.0  18665.333333      79  \n",
       "...     ...  ...  ...     ...  ...  ...  ...       ...           ...     ...  \n",
       "511067  0.0  0.0  0.0  8785.2  0.0  0.0    9  152180.4  16908.933333     122  \n",
       "511068  0.0  0.0  0.0  8785.2  0.0  0.0    9  152180.4  16908.933333     122  \n",
       "511069  0.0  0.0  0.0  8785.2  0.0  0.0    9  152180.4  16908.933333     122  \n",
       "511070  0.0  0.0  0.0  8785.2  0.0  0.0    9  152180.4  16908.933333     122  \n",
       "511071  0.0  0.0  0.0  8785.2  0.0  0.0    9  152180.4  16908.933333     122  \n",
       "\n",
       "[419277 rows x 39 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create CSV file for dataset\n",
    "#df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot Encoding for DEFECT_GROUP_ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique HEAT_ID of Recipes: ['SU' 'SH' 'DM' 'OTH' 'MET' 'CCTO' 'IDF' 'PR' 'PK' 'EQ']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique HEAT_ID of Recipes: {df['DEFECT_GROUP_ID'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummies = pd.get_dummies(df.DEFECT_GROUP_ID)\n",
    "#dummies.head(3)\n",
    "\n",
    "#dummies = pd.get_dummies(df.DEFECT_TYPE)\n",
    "#dummies.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concate \n",
    "#df = pd.concat([df,dummies.drop(36,axis='columns')],axis='columns')\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([         'PIECE_ID',           'HEAT_ID',       'DEFECT_TYPE',\n",
       "             'DEFECT_NAME',   'DEFECT_GROUP_ID', 'DEFECT_GROUP_Name',\n",
       "                       112,                 113,                 114,\n",
       "                       115,                 116,                 117,\n",
       "                       118,                 119,                 120,\n",
       "                       121,                 122,                 124,\n",
       "                       125,                 126,                 166,\n",
       "                       180,                 181,                 182,\n",
       "                       183,                 190,                 207,\n",
       "                       208,                 209,                 210,\n",
       "                       211,                 212,                 213,\n",
       "                       214,                 215,               'Num',\n",
       "                     'Sum',              'Mean',            'Repeat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>HEAT_ID</th>\n",
       "      <th>DEFECT_GROUP_ID</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>...</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>Sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1701192</td>\n",
       "      <td>SU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50306.6</td>\n",
       "      <td>3473.6</td>\n",
       "      <td>2215.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1701192</td>\n",
       "      <td>SU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50306.6</td>\n",
       "      <td>3473.6</td>\n",
       "      <td>2215.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1701192</td>\n",
       "      <td>SU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50306.6</td>\n",
       "      <td>3473.6</td>\n",
       "      <td>2215.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1701192</td>\n",
       "      <td>SU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50306.6</td>\n",
       "      <td>3473.6</td>\n",
       "      <td>2215.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1701192</td>\n",
       "      <td>SU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50306.6</td>\n",
       "      <td>3473.6</td>\n",
       "      <td>2215.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419272</th>\n",
       "      <td>511067</td>\n",
       "      <td>1811206</td>\n",
       "      <td>OTH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32147.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51038.7</td>\n",
       "      <td>6841.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8785.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152180.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419273</th>\n",
       "      <td>511068</td>\n",
       "      <td>1811206</td>\n",
       "      <td>OTH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32147.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51038.7</td>\n",
       "      <td>6841.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8785.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152180.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419274</th>\n",
       "      <td>511069</td>\n",
       "      <td>1811206</td>\n",
       "      <td>DM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32147.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51038.7</td>\n",
       "      <td>6841.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8785.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152180.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419275</th>\n",
       "      <td>511070</td>\n",
       "      <td>1811206</td>\n",
       "      <td>DM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32147.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51038.7</td>\n",
       "      <td>6841.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8785.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152180.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419276</th>\n",
       "      <td>511071</td>\n",
       "      <td>1811206</td>\n",
       "      <td>OTH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32147.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51038.7</td>\n",
       "      <td>6841.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8785.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152180.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>419277 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  HEAT_ID DEFECT_GROUP_ID  112      113     114     115  116  \\\n",
       "0            0  1701192              SU  0.0  50306.6  3473.6  2215.8  0.0   \n",
       "1            1  1701192              SU  0.0  50306.6  3473.6  2215.8  0.0   \n",
       "2            2  1701192              SU  0.0  50306.6  3473.6  2215.8  0.0   \n",
       "3            3  1701192              SU  0.0  50306.6  3473.6  2215.8  0.0   \n",
       "4            4  1701192              SU  0.0  50306.6  3473.6  2215.8  0.0   \n",
       "...        ...      ...             ...  ...      ...     ...     ...  ...   \n",
       "419272  511067  1811206             OTH  0.0  32147.5     0.0     0.0  0.0   \n",
       "419273  511068  1811206             OTH  0.0  32147.5     0.0     0.0  0.0   \n",
       "419274  511069  1811206              DM  0.0  32147.5     0.0     0.0  0.0   \n",
       "419275  511070  1811206              DM  0.0  32147.5     0.0     0.0  0.0   \n",
       "419276  511071  1811206             OTH  0.0  32147.5     0.0     0.0  0.0   \n",
       "\n",
       "            117     118  ...  207  208  209  210  211  212     213  214  215  \\\n",
       "0           0.0     0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0   \n",
       "1           0.0     0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0   \n",
       "2           0.0     0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0   \n",
       "3           0.0     0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0   \n",
       "4           0.0     0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0   \n",
       "...         ...     ...  ...  ...  ...  ...  ...  ...  ...     ...  ...  ...   \n",
       "419272  51038.7  6841.5  ...  0.0  0.0  0.0  0.0  0.0  0.0  8785.2  0.0  0.0   \n",
       "419273  51038.7  6841.5  ...  0.0  0.0  0.0  0.0  0.0  0.0  8785.2  0.0  0.0   \n",
       "419274  51038.7  6841.5  ...  0.0  0.0  0.0  0.0  0.0  0.0  8785.2  0.0  0.0   \n",
       "419275  51038.7  6841.5  ...  0.0  0.0  0.0  0.0  0.0  0.0  8785.2  0.0  0.0   \n",
       "419276  51038.7  6841.5  ...  0.0  0.0  0.0  0.0  0.0  0.0  8785.2  0.0  0.0   \n",
       "\n",
       "             Sum  \n",
       "0        55996.0  \n",
       "1        55996.0  \n",
       "2        55996.0  \n",
       "3        55996.0  \n",
       "4        55996.0  \n",
       "...          ...  \n",
       "419272  152180.4  \n",
       "419273  152180.4  \n",
       "419274  152180.4  \n",
       "419275  152180.4  \n",
       "419276  152180.4  \n",
       "\n",
       "[419277 rows x 33 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['PIECE_ID','DEFECT_TYPE', 'DEFECT_NAME', 'DEFECT_GROUP_Name','Num','Mean','Repeat'])\n",
    "df.reset_index(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HEAT_ID</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>...</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>Sum</th>\n",
       "      <th>DEFECT_GROUP_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1701192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50306.6</td>\n",
       "      <td>3473.6</td>\n",
       "      <td>2215.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55996.0</td>\n",
       "      <td>SU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1701192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50306.6</td>\n",
       "      <td>3473.6</td>\n",
       "      <td>2215.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55996.0</td>\n",
       "      <td>SU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1701192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50306.6</td>\n",
       "      <td>3473.6</td>\n",
       "      <td>2215.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55996.0</td>\n",
       "      <td>SU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1701192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50306.6</td>\n",
       "      <td>3473.6</td>\n",
       "      <td>2215.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55996.0</td>\n",
       "      <td>SU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1701192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50306.6</td>\n",
       "      <td>3473.6</td>\n",
       "      <td>2215.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55996.0</td>\n",
       "      <td>SU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419272</th>\n",
       "      <td>1811206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32147.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51038.7</td>\n",
       "      <td>6841.5</td>\n",
       "      <td>6534.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8785.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152180.4</td>\n",
       "      <td>OTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419273</th>\n",
       "      <td>1811206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32147.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51038.7</td>\n",
       "      <td>6841.5</td>\n",
       "      <td>6534.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8785.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152180.4</td>\n",
       "      <td>OTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419274</th>\n",
       "      <td>1811206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32147.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51038.7</td>\n",
       "      <td>6841.5</td>\n",
       "      <td>6534.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8785.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152180.4</td>\n",
       "      <td>DM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419275</th>\n",
       "      <td>1811206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32147.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51038.7</td>\n",
       "      <td>6841.5</td>\n",
       "      <td>6534.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8785.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152180.4</td>\n",
       "      <td>DM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419276</th>\n",
       "      <td>1811206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32147.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51038.7</td>\n",
       "      <td>6841.5</td>\n",
       "      <td>6534.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8785.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152180.4</td>\n",
       "      <td>OTH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>419277 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        HEAT_ID  112      113     114     115  116      117     118     119  \\\n",
       "0       1701192  0.0  50306.6  3473.6  2215.8  0.0      0.0     0.0     0.0   \n",
       "1       1701192  0.0  50306.6  3473.6  2215.8  0.0      0.0     0.0     0.0   \n",
       "2       1701192  0.0  50306.6  3473.6  2215.8  0.0      0.0     0.0     0.0   \n",
       "3       1701192  0.0  50306.6  3473.6  2215.8  0.0      0.0     0.0     0.0   \n",
       "4       1701192  0.0  50306.6  3473.6  2215.8  0.0      0.0     0.0     0.0   \n",
       "...         ...  ...      ...     ...     ...  ...      ...     ...     ...   \n",
       "419272  1811206  0.0  32147.5     0.0     0.0  0.0  51038.7  6841.5  6534.9   \n",
       "419273  1811206  0.0  32147.5     0.0     0.0  0.0  51038.7  6841.5  6534.9   \n",
       "419274  1811206  0.0  32147.5     0.0     0.0  0.0  51038.7  6841.5  6534.9   \n",
       "419275  1811206  0.0  32147.5     0.0     0.0  0.0  51038.7  6841.5  6534.9   \n",
       "419276  1811206  0.0  32147.5     0.0     0.0  0.0  51038.7  6841.5  6534.9   \n",
       "\n",
       "        120  ...  208  209  210  211  212     213  214  215       Sum  \\\n",
       "0       0.0  ...  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0   55996.0   \n",
       "1       0.0  ...  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0   55996.0   \n",
       "2       0.0  ...  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0   55996.0   \n",
       "3       0.0  ...  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0   55996.0   \n",
       "4       0.0  ...  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0   55996.0   \n",
       "...     ...  ...  ...  ...  ...  ...  ...     ...  ...  ...       ...   \n",
       "419272  0.0  ...  0.0  0.0  0.0  0.0  0.0  8785.2  0.0  0.0  152180.4   \n",
       "419273  0.0  ...  0.0  0.0  0.0  0.0  0.0  8785.2  0.0  0.0  152180.4   \n",
       "419274  0.0  ...  0.0  0.0  0.0  0.0  0.0  8785.2  0.0  0.0  152180.4   \n",
       "419275  0.0  ...  0.0  0.0  0.0  0.0  0.0  8785.2  0.0  0.0  152180.4   \n",
       "419276  0.0  ...  0.0  0.0  0.0  0.0  0.0  8785.2  0.0  0.0  152180.4   \n",
       "\n",
       "        DEFECT_GROUP_ID  \n",
       "0                    SU  \n",
       "1                    SU  \n",
       "2                    SU  \n",
       "3                    SU  \n",
       "4                    SU  \n",
       "...                 ...  \n",
       "419272              OTH  \n",
       "419273              OTH  \n",
       "419274               DM  \n",
       "419275               DM  \n",
       "419276              OTH  \n",
       "\n",
       "[419277 rows x 32 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=df[['HEAT_ID',112,113,114,115,116,117,118,119,120,121,122,124,125,126,166,180,181,182,183,190,207,208,209,210,211,212,213,214,215,'Sum','DEFECT_GROUP_ID']]\n",
    "df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(419277, 32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make area(SqFt) vs price plot\n",
    "#%matplotlib inline\n",
    "#Make label area and price\n",
    "#plt.xlabel('HEAT_ID')\n",
    "#plt.ylabel('DEFECT_GROUP_ID')\n",
    "#plt.scatter(df2.HEAT_ID,df.DEFECT_GROUP_ID, color ='blue', marker='.') #ekhane kon columns ar plot hobe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3 = df2.drop_duplicates()\n",
    "#df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling as pp\n",
    "#pp.ProfileReport(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Model and Tharin the Dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split The Data X and y :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the data_process file which includes data preprocessing functions\n",
    "from data_preprocess import*\n",
    "\n",
    "#Loading all the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HEAT_ID</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>...</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>Sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1701192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50306.6</td>\n",
       "      <td>3473.6</td>\n",
       "      <td>2215.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1701192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50306.6</td>\n",
       "      <td>3473.6</td>\n",
       "      <td>2215.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1701192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50306.6</td>\n",
       "      <td>3473.6</td>\n",
       "      <td>2215.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55996.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HEAT_ID  112      113     114     115  116  117  118  119  120  ...  207  \\\n",
       "0  1701192  0.0  50306.6  3473.6  2215.8  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "1  1701192  0.0  50306.6  3473.6  2215.8  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "2  1701192  0.0  50306.6  3473.6  2215.8  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "\n",
       "   208  209  210  211  212  213  214  215      Sum  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  55996.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  55996.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  55996.0  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df2.drop(['DEFECT_GROUP_ID'],axis='columns')\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    SU\n",
       "1    SU\n",
       "2    SU\n",
       "Name: DEFECT_GROUP_ID, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df2.DEFECT_GROUP_ID\n",
    "\n",
    "y.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#split Train and test X,y data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X_train :335421\n",
      "Length of y_train :335421\n",
      "Length of X_test :83856\n",
      "Length of y_test :83856\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of X_train :{len(X_train)}\")\n",
    "print(f\"Length of y_train :{len(y_train)}\")\n",
    "print(f\"Length of X_test :{len(X_test)}\")\n",
    "print(f\"Length of y_test :{len(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HEAT_ID</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>...</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>Sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1701192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50306.6</td>\n",
       "      <td>3473.6</td>\n",
       "      <td>2215.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1701192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50306.6</td>\n",
       "      <td>3473.6</td>\n",
       "      <td>2215.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1701192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50306.6</td>\n",
       "      <td>3473.6</td>\n",
       "      <td>2215.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1701192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50306.6</td>\n",
       "      <td>3473.6</td>\n",
       "      <td>2215.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1701192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50306.6</td>\n",
       "      <td>3473.6</td>\n",
       "      <td>2215.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419272</th>\n",
       "      <td>1811206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32147.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51038.7</td>\n",
       "      <td>6841.5</td>\n",
       "      <td>6534.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8785.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152180.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419273</th>\n",
       "      <td>1811206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32147.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51038.7</td>\n",
       "      <td>6841.5</td>\n",
       "      <td>6534.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8785.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152180.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419274</th>\n",
       "      <td>1811206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32147.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51038.7</td>\n",
       "      <td>6841.5</td>\n",
       "      <td>6534.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8785.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152180.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419275</th>\n",
       "      <td>1811206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32147.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51038.7</td>\n",
       "      <td>6841.5</td>\n",
       "      <td>6534.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8785.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152180.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419276</th>\n",
       "      <td>1811206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32147.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51038.7</td>\n",
       "      <td>6841.5</td>\n",
       "      <td>6534.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8785.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152180.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>419277 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        HEAT_ID  112      113     114     115  116      117     118     119  \\\n",
       "0       1701192  0.0  50306.6  3473.6  2215.8  0.0      0.0     0.0     0.0   \n",
       "1       1701192  0.0  50306.6  3473.6  2215.8  0.0      0.0     0.0     0.0   \n",
       "2       1701192  0.0  50306.6  3473.6  2215.8  0.0      0.0     0.0     0.0   \n",
       "3       1701192  0.0  50306.6  3473.6  2215.8  0.0      0.0     0.0     0.0   \n",
       "4       1701192  0.0  50306.6  3473.6  2215.8  0.0      0.0     0.0     0.0   \n",
       "...         ...  ...      ...     ...     ...  ...      ...     ...     ...   \n",
       "419272  1811206  0.0  32147.5     0.0     0.0  0.0  51038.7  6841.5  6534.9   \n",
       "419273  1811206  0.0  32147.5     0.0     0.0  0.0  51038.7  6841.5  6534.9   \n",
       "419274  1811206  0.0  32147.5     0.0     0.0  0.0  51038.7  6841.5  6534.9   \n",
       "419275  1811206  0.0  32147.5     0.0     0.0  0.0  51038.7  6841.5  6534.9   \n",
       "419276  1811206  0.0  32147.5     0.0     0.0  0.0  51038.7  6841.5  6534.9   \n",
       "\n",
       "        120  ...  207  208  209  210  211  212     213  214  215       Sum  \n",
       "0       0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0   55996.0  \n",
       "1       0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0   55996.0  \n",
       "2       0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0   55996.0  \n",
       "3       0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0   55996.0  \n",
       "4       0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0   55996.0  \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...     ...  ...  ...       ...  \n",
       "419272  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  8785.2  0.0  0.0  152180.4  \n",
       "419273  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  8785.2  0.0  0.0  152180.4  \n",
       "419274  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  8785.2  0.0  0.0  152180.4  \n",
       "419275  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  8785.2  0.0  0.0  152180.4  \n",
       "419276  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  8785.2  0.0  0.0  152180.4  \n",
       "\n",
       "[419277 rows x 31 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          SU\n",
       "1          SU\n",
       "2          SU\n",
       "3          SU\n",
       "4          SU\n",
       "         ... \n",
       "419272    OTH\n",
       "419273    OTH\n",
       "419274     DM\n",
       "419275     DM\n",
       "419276    OTH\n",
       "Name: DEFECT_GROUP_ID, Length: 419277, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4645105895821408"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(solver='liblinear',multi_class='ovr' ,C=10)\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['OTH'], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict([[1701194, 0.0, 0.0, 0.0, 0.0, 0.0,0.0, 0.0, 4545.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4545.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4365221331806907"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(X,y)\n",
    "\n",
    "#Predict Output\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hamming_loss : 0.5634778668193093\n",
      "f1_score : 0.1604995232317231\n",
      "recall_score : 0.4365221331806907\n",
      "precision_score : 0.4365221331806907\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "prediction = model.predict(X_test)\n",
    "\n",
    "print(f\"hamming_loss : {metrics.hamming_loss(y_test, prediction)}\")\n",
    "print(f\"f1_score : {f1_score(y_test, prediction, average='macro')}\")\n",
    "print(f\"recall_score : {recall_score(y_test, prediction, average='micro')}\")\n",
    "print(f\"precision_score : {precision_score(y_test, prediction, average='micro')}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple Ensemble Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max Voting : “VotingClassifier” module in sklearn as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.464605991223049"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "model1 = LogisticRegression(random_state=1)\n",
    "model2 = DecisionTreeClassifier(random_state=1)\n",
    "model3 = KNeighborsClassifier()\n",
    "model4 = RandomForestClassifier(max_depth=10, n_estimators=40)\n",
    "model = VotingClassifier(estimators=[('lr', model1), ('dt', model2),('kn',model3),('RF',model4)], voting='hard')\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DM'], dtype=object)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[1701194, 0.0, 0.0, 0.0, 0.0, 0.0,0.0, 0.0, 4545.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4545.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.ensemble import VotingClassifier\\nmodel1 = RandomForestClassifier(max_depth=10, n_estimators=40)\\nmodel2 = DecisionTreeClassifier(random_state=1)\\nmodel = VotingClassifier(estimators=[('RF', model1), ('dt', model2)], voting='hard')\\nmodel.fit(X_train,y_train)\\nmodel.score(X_test,y_test)\\n\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "model1 = RandomForestClassifier(max_depth=10, n_estimators=40)\n",
    "model2 = DecisionTreeClassifier(random_state=1)\n",
    "model = VotingClassifier(estimators=[('RF', model1), ('dt', model2)], voting='hard')\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_test,y_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.predict([[1701194, 0.0, 0.0, 0.0, 0.0, 0.0,0.0, 0.0, 4545.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4545.9]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Ensemble Techniques:: Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier, VotingClassifier\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import cross_val_score\\n\\nlr_clf = LogisticRegression() \\ndt_clf = DecisionTreeClassifier() \\nrf_clf = RandomForestClassifier() \\net_clf = ExtraTreesClassifier() \\nknn_clf = KNeighborsClassifier() \\n\\nclassifiers =[lr_clf, dt_clf, rf_clf, et_clf, knn_clf]\\nfor clf in classifiers:\\n    clf_scores = cross_val_score(clf, X_train, y_train, cv = 10)\\n    bagging_clf = BaggingClassifier(clf, max_samples=0.4, max_features=10, random_state=0)\\n    bagging_clf_scores = cross_val_score(bagging_clf, X_train, y_train, cv = 10)\\n    print(clf.__class__.__name__, \":::: Mean:\", clf_scores.mean(), \", Std Dev:\", clf_scores.std())\\n    print(\"Bagging\", clf.__class__.__name__, \":::: Mean:\", bagging_clf_scores.mean(), \"Std Dev:\", bagging_clf_scores.std(), \"\\n\")\\n\\nensembler = VotingClassifier(estimators=[(\\'LogisticRegression\\', lr_clf), (\\'DecisionTreeClassifier\\', dt_clf),\\n                                        (\\'RandomForestClassifier\\', rf_clf), (\\'ExtraTreesClassifier\\', et_clf),\\n                                        (\\'KNeighborsClassifier\\', knn_clf)], voting = \\'hard\\')\\n\\n\\nensembler_scores = cross_val_score(ensembler, X_train, y_train, cv = 10)\\nprint(ensembler.__class__.__name__, \":::: Mean:\", ensembler_scores.mean(), \"Std Dev:\", clf_scores.std())\\n\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lr_clf = LogisticRegression() \n",
    "dt_clf = DecisionTreeClassifier() \n",
    "rf_clf = RandomForestClassifier() \n",
    "et_clf = ExtraTreesClassifier() \n",
    "knn_clf = KNeighborsClassifier() \n",
    "\n",
    "classifiers =[lr_clf, dt_clf, rf_clf, et_clf, knn_clf]\n",
    "for clf in classifiers:\n",
    "    clf_scores = cross_val_score(clf, X_train, y_train, cv = 10)\n",
    "    bagging_clf = BaggingClassifier(clf, max_samples=0.4, max_features=10, random_state=0)\n",
    "    bagging_clf_scores = cross_val_score(bagging_clf, X_train, y_train, cv = 10)\n",
    "    print(clf.__class__.__name__, \":::: Mean:\", clf_scores.mean(), \", Std Dev:\", clf_scores.std())\n",
    "    print(\"Bagging\", clf.__class__.__name__, \":::: Mean:\", bagging_clf_scores.mean(), \"Std Dev:\", bagging_clf_scores.std(), \"\\n\")\n",
    "\n",
    "ensembler = VotingClassifier(estimators=[('LogisticRegression', lr_clf), ('DecisionTreeClassifier', dt_clf),\n",
    "                                        ('RandomForestClassifier', rf_clf), ('ExtraTreesClassifier', et_clf),\n",
    "                                        ('KNeighborsClassifier', knn_clf)], voting = 'hard')\n",
    "\n",
    "\n",
    "ensembler_scores = cross_val_score(ensembler, X_train, y_train, cv = 10)\n",
    "print(ensembler.__class__.__name__, \":::: Mean:\", ensembler_scores.mean(), \"Std Dev:\", clf_scores.std())\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.ensemble import BaggingClassifier\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom matplotlib.colors import ListedColormap\\n#Bagging 500 trees\\nbag_clf = BaggingClassifier(\\n    DecisionTreeClassifier(random_state=42), n_estimators=500,\\n    max_samples=100, oob_score=False, bootstrap=True, random_state=42)\\nbag_clf.fit(X_train, y_train)\\ny_pred = bag_clf.predict(X_test)\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from matplotlib.colors import ListedColormap\n",
    "#Bagging 500 trees\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(random_state=42), n_estimators=500,\n",
    "    max_samples=100, oob_score=False, bootstrap=True, random_state=42)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Accuracy of Bagged Trees\\nfrom sklearn.metrics import accuracy_score\\nprint('Accuracy of Bagged Trees: {}'.format(accuracy_score(y_test, y_pred)))\\n\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Accuracy of Bagged Trees\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy of Bagged Trees: {}'.format(accuracy_score(y_test, y_pred)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntree_clf = DecisionTreeClassifier(random_state=42)\\ntree_clf.fit(X_train, y_train)\\ny_pred_tree = tree_clf.predict(X_test)\\nprint('Accuracy of a Single Tree: {}'.format(accuracy_score(y_test, y_pred_tree)))\\n\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "y_pred_tree = tree_clf.predict(X_test)\n",
    "print('Accuracy of a Single Tree: {}'.format(accuracy_score(y_test, y_pred_tree)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bag_clf.predict([[1710018,0,47683.0,0,9217.5,0,8420.0,0,0,8929.0,26208.6,0,6673.3,0,52351.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.ensemble import BaggingClassifier\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom matplotlib.colors import ListedColormap\\nfrom sklearn.metrics import accuracy_score\\n\\n#Bagging 500 trees\\nbag_clf = BaggingClassifier(\\n    DecisionTreeClassifier(random_state=42), n_estimators=500,\\n    max_samples=100, oob_score=True, bootstrap=True, random_state=42)\\nbag_clf.fit(X_train, y_train)\\ny_pred = bag_clf.predict(X_test)\\n\\nprint('OOB score is {}'.format(bag_clf.oob_score_))\\nprint('Accuracy of Bagged Trees: {}'.format(accuracy_score(y_test, y_pred)))\\n\\n\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Bagging 500 trees\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(random_state=42), n_estimators=500,\n",
    "    max_samples=100, oob_score=True, bootstrap=True, random_state=42)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "\n",
    "print('OOB score is {}'.format(bag_clf.oob_score_))\n",
    "print('Accuracy of Bagged Trees: {}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The OOB decision function for each training istances is also available through oob_decision_function_ variable. In this case (since the base estimator\n",
    "#DecisionTreeClassifier() has a predict_proba() method) the decision function return the class probabilities for each training instance.\n",
    "#Let's print the first five observations.\n",
    "#bag_clf.oob_decision_function_[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Ensemble Techniques::Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\\nfrom xgboost import XGBClassifier\\nfrom sklearn.model_selection import cross_val_score\\n\\nab_clf = AdaBoostClassifier() \\ngb_clf = GradientBoostingClassifier() \\nxgb_clf = XGBClassifier() \\n\\nensembler = VotingClassifier(estimators=[(\\'AdaBoostClassifier\\', ab_clf), (\\'GradientBoostingClassifier\\', gb_clf),\\n                                        (\\'XGBClassifier\\', xgb_clf)], voting = \\'hard\\')\\n\\nclassifiers =[ab_clf, gb_clf, xgb_clf, ensembler]\\nfor clf in classifiers:\\n    clf_scores = cross_val_score(clf, X_train, y_train, cv = 10)\\n    print(clf.__class__.__name__, \":::: Mean:\", clf_scores.mean(), \"Std Dev:\", clf_scores.std())\\n    \\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "ab_clf = AdaBoostClassifier() \n",
    "gb_clf = GradientBoostingClassifier() \n",
    "xgb_clf = XGBClassifier() \n",
    "\n",
    "ensembler = VotingClassifier(estimators=[('AdaBoostClassifier', ab_clf), ('GradientBoostingClassifier', gb_clf),\n",
    "                                        ('XGBClassifier', xgb_clf)], voting = 'hard')\n",
    "\n",
    "classifiers =[ab_clf, gb_clf, xgb_clf, ensembler]\n",
    "for clf in classifiers:\n",
    "    clf_scores = cross_val_score(clf, X_train, y_train, cv = 10)\n",
    "    print(clf.__class__.__name__, \":::: Mean:\", clf_scores.mean(), \"Std Dev:\", clf_scores.std())\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Ensemble Techniques:: Bagging meta-estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.ensemble import BaggingClassifier\\nfrom sklearn import tree\\nmodel = BaggingClassifier(tree.DecisionTreeClassifier(random_state=1))\\nmodel.fit(X_train, y_train)\\nmodel.score(X_test,y_test)\\n'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import tree\n",
    "model = BaggingClassifier(tree.DecisionTreeClassifier(random_state=1))\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test,y_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.predict([[1710018,0,47683.0,0,9217.5,0,8420.0,0,0,8929.0,26208.6,0,6673.3,0,52351.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Ensemble Techniques::Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\nrf = RandomForestClassifier(max_depth=10, n_estimators=40)\\nrf.fit(X_train, y_train)\\nrf.score(X_test, y_test)\\n'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=10, n_estimators=40)\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\npredict_train = rf.predict(X_train)\\nprint('\\nTarget on train data',predict_train)\\n\\n# Accuray Score on train dataset\\naccuracy_train = accuracy_score(y_train,predict_train)\\nprint('\\n accuracy_score on train dataset :',accuracy_train)\\n\\n# predict the target on the test dataset\\npredict_test = rf.predict(X_test)\\nprint('\\nTarget on test data:',predict_test)\\n\\n# Accuracy Score on test dataset\\naccuracy_test = accuracy_score(y_test,predict_test)\\nprint('\\naccuracy_score on test dataset : ', accuracy_test)\\n\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "predict_train = rf.predict(X_train)\n",
    "print('\\nTarget on train data',predict_train)\n",
    "\n",
    "# Accuray Score on train dataset\n",
    "accuracy_train = accuracy_score(y_train,predict_train)\n",
    "print('\\n accuracy_score on train dataset :',accuracy_train)\n",
    "\n",
    "# predict the target on the test dataset\n",
    "predict_test = rf.predict(X_test)\n",
    "print('\\nTarget on test data:',predict_test)\n",
    "\n",
    "# Accuracy Score on test dataset\n",
    "accuracy_test = accuracy_score(y_test,predict_test)\n",
    "print('\\naccuracy_score on test dataset : ', accuracy_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf.predict([[1710018,0,47683.0,0,9217.5,0,8420.0,0,0,8929.0,26208.6,0,6673.3,0,52351.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OOB Evaluation in Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.metrics import accuracy_score\\n\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\n\\nrnd_clf = RandomForestClassifier(n_estimators=31, oob_score = True, random_state=42)\\nrnd_clf.fit(X_train, y_train)\\n\\ny_pred_rf = rnd_clf.predict(X_test)\\n\\nprint('Accuracy of Random Forest algorithm: {}'.format(accuracy_score(y_test, y_pred_rf)))\\nprint('OOB score is {}'.format(rnd_clf.oob_score_))\\n\\n  \""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##https://mmuratarat.github.io/2019-08-06/ensemble-learning-details-examples\n",
    "'''\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=31, oob_score = True, random_state=42)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rnd_clf.predict(X_test)\n",
    "\n",
    "print('Accuracy of Random Forest algorithm: {}'.format(accuracy_score(y_test, y_pred_rf)))\n",
    "print('OOB score is {}'.format(rnd_clf.oob_score_))\n",
    "\n",
    "  '''                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rnd_clf.predict([[1710018,0,47683.0,0,9217.5,0,8420.0,0,0,8929.0,26208.6,0,6673.3,0,52351.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rnd_clf.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fifth_small = rnd_clf.estimators_[5]\n",
    "#fifth_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport matplotlib.pyplot as plt\\nclf = RandomForestClassifier(n_estimators=500, max_leaf_nodes = 16, random_state=0, n_jobs=-1)\\n\\n# Train model\\nmodel = clf.fit(X, y)\\n\\n# Calculate feature importances\\nimportances = model.feature_importances_\\n'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create decision tree classifer object\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes = 16, random_state=0, n_jobs=-1)\n",
    "\n",
    "# Train model\n",
    "model = clf.fit(X, y)\n",
    "\n",
    "# Calculate feature importances\n",
    "importances = model.feature_importances_\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_rf = model.predict(X_test)\n",
    "\n",
    "#print('Accuracy of Random Forest algorithm: {}'.format(accuracy_score(y_test, y_pred_rf)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Ensemble Techniques::AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.ensemble import AdaBoostClassifier\\nAda_model = AdaBoostClassifier(random_state=1)\\nAda_model.fit(X_train, y_train)\\nAda_model.score(X_test,y_test)\\n'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "Ada_model = AdaBoostClassifier(random_state=1)\n",
    "Ada_model.fit(X_train, y_train)\n",
    "Ada_model.score(X_test,y_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ada_model.predict([[1710018,0,47683.0,0,9217.5,0,8420.0,0,0,8929.0,26208.6,0,6673.3,0,52351.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.ensemble import AdaBoostClassifier\\nAda_model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=100), n_estimators=200,\\nalgorithm=\"SAMME.R\", learning_rate=0.5)\\nAda_model.fit(X_train, y_train)\\nAda_model.score(X_test,y_test)\\n'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "Ada_model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=100), n_estimators=200,\n",
    "algorithm=\"SAMME.R\", learning_rate=0.5)\n",
    "Ada_model.fit(X_train, y_train)\n",
    "Ada_model.score(X_test,y_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for test dataset\n",
    "#y_pred_AdaBoost = Ada_model.predict(X_test)\n",
    "\n",
    "#print('Accuracy of AdaBoost algorithm: {}'.format(accuracy_score(y_test, y_pred_AdaBoost)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\npredict_train = Ada_model.predict(X_train)\\nprint('\\nTarget on train data',predict_train)\\n\\n# Accuray Score on train dataset\\naccuracy_train = accuracy_score(y_train,predict_train)\\nprint('\\n accuracy_score on train dataset :',accuracy_train)\\n\\n# predict the target on the test dataset\\npredict_test = Ada_model.predict(X_test)\\nprint('\\nTarget on test data:',predict_test)\\n\\n# Accuracy Score on test dataset\\naccuracy_test = accuracy_score(y_test,predict_test)\\nprint('\\naccuracy_score on test dataset : ', accuracy_test)\\n\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "predict_train = Ada_model.predict(X_train)\n",
    "print('\\nTarget on train data',predict_train)\n",
    "\n",
    "# Accuray Score on train dataset\n",
    "accuracy_train = accuracy_score(y_train,predict_train)\n",
    "print('\\n accuracy_score on train dataset :',accuracy_train)\n",
    "\n",
    "# predict the target on the test dataset\n",
    "predict_test = Ada_model.predict(X_test)\n",
    "print('\\nTarget on test data:',predict_test)\n",
    "\n",
    "# Accuracy Score on test dataset\n",
    "accuracy_test = accuracy_score(y_test,predict_test)\n",
    "print('\\naccuracy_score on test dataset : ', accuracy_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ada_model.predict([[1710018,0,47683.0,0,9217.5,0,8420.0,0,0,8929.0,26208.6,0,6673.3,0,52351.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Ensemble Techniques::Gradient Boosting (GBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.ensemble import GradientBoostingClassifier\\nGBM_model= GradientBoostingClassifier(learning_rate=0.01,random_state=1)\\nGBM_model.fit(X_train, y_train)\\nGBM_model.score(X_test,y_test)\\n\\n\\n\\n\\npredict_train = GBM_model.predict(X_train)\\nprint('\\nTarget on train data',predict_train)\\n\\n# Accuray Score on train dataset\\naccuracy_train = accuracy_score(y_train,predict_train)\\nprint('\\nAccuracy_score on train dataset :',accuracy_train)\\n\\n# predict the target on the test dataset\\npredict_test = GBM_model.predict(X_test)\\nprint('\\nTarget on test data:',predict_test)\\n\\n# Accuracy Score on test dataset\\naccuracy_test = accuracy_score(y_test,predict_test)\\nprint('\\naccuracy_score on test dataset : ', accuracy_test)\\n\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GBM_model= GradientBoostingClassifier(learning_rate=0.01,random_state=1)\n",
    "GBM_model.fit(X_train, y_train)\n",
    "GBM_model.score(X_test,y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "predict_train = GBM_model.predict(X_train)\n",
    "print('\\nTarget on train data',predict_train)\n",
    "\n",
    "# Accuray Score on train dataset\n",
    "accuracy_train = accuracy_score(y_train,predict_train)\n",
    "print('\\nAccuracy_score on train dataset :',accuracy_train)\n",
    "\n",
    "# predict the target on the test dataset\n",
    "predict_test = GBM_model.predict(X_test)\n",
    "print('\\nTarget on test data:',predict_test)\n",
    "\n",
    "# Accuracy Score on test dataset\n",
    "accuracy_test = accuracy_score(y_test,predict_test)\n",
    "print('\\naccuracy_score on test dataset : ', accuracy_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GBM_model.predict([[1710018,0,47683.0,0,9217.5,0,8420.0,0,0,8929.0,26208.6,0,6673.3,0,52351.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Ensemble Techniques::XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport xgboost as xgb\\nxgb_model=xgb.XGBClassifier(random_state=1,learning_rate=0.01)\\nxgb_model.fit(X_train, y_train)\\nxgb_model.score(X_test,y_test)\\n'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import xgboost as xgb\n",
    "xgb_model=xgb.XGBClassifier(random_state=1,learning_rate=0.01)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_model.score(X_test,y_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb_model.predict([[1710018,0,47683.0,0,9217.5,0,8420.0,0,0,8929.0,26208.6,0,6673.3,0,52351.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]])\n",
    "#preds = xgb_model.predict(X_test)\n",
    "#preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Ensemble Techniques::Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import lightgbm as lgb\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm = LGBMClassifier(objective='multiclass', random_state=5)\n",
    "lgbm.fit(X, y)\n",
    "y_pred = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43240793741652356"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target on train data ['OTH' 'OTH' 'OTH' ... 'MET' 'OTH' 'DM']\n",
      "\n",
      "Accuracy_score on train dataset : 0.432203111910107\n",
      "\n",
      "Target on test data: ['OTH' 'DM' 'OTH' ... 'DM' 'DM' 'OTH']\n",
      "\n",
      "accuracy_score on test dataset :  0.43240793741652356\n"
     ]
    }
   ],
   "source": [
    "predict_train = lgbm.predict(X_train)\n",
    "print('\\nTarget on train data',predict_train)\n",
    "\n",
    "# Accuray Score on train dataset\n",
    "accuracy_train = accuracy_score(y_train,predict_train)\n",
    "print('\\nAccuracy_score on train dataset :',accuracy_train)\n",
    "\n",
    "# predict the target on the test dataset\n",
    "predict_test = lgbm.predict(X_test)\n",
    "print('\\nTarget on test data:',predict_test)\n",
    "\n",
    "# Accuracy Score on test dataset\n",
    "accuracy_test = accuracy_score(y_test,predict_test)\n",
    "print('\\naccuracy_score on test dataset : ', accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EQ'], dtype=object)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm.predict([[1710018,0,47683.0,0,9217.5,0,8420.0,0,0,8929.0,26208.6,0,6673.3,0,52351.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Ensemble Techniques::CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahim\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:672: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "Cat=CatBoostClassifier(verbose=0, n_estimators=100)\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(Cat, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\n",
    "\n",
    "\n",
    "Cat.fit(X,y)\n",
    "Cat.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#from sklearn.datasets import make_multilabel_classification\n",
    "\n",
    "# this will generate a random multi-label dataset\n",
    "#X, y = make_multilabel_classification(sparse = True, n_labels = 20, allow_unlabeled = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=0)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#clf = DecisionTreeClassifier(random_state=0)\n",
    "#clf.fit(X,y)\n",
    "#cross_val_score(clf, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49741578956155474"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clf.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['OTH'], dtype=object)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clf.predict([[1710018,0,47683.0,0,9217.5,0,8420.0,0,0,8929.0,26208.6,0,6673.3,0,52351.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len([1710018,0,47683.0,0,9217.5,0,8420.0,0,0,8929.0,26208.6,0,6673.3,0,52351.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.ensemble import RandomForestClassifier\\n#from sklearn.datasets import make_classification\\n#X, y = make_classification(n_samples=1000, n_features=31,\\n#                           n_informative=2, n_redundant=0,\\n#                           random_state=0, shuffle=False)\\nrf = RandomForestClassifier(max_depth=10, n_estimators=40)\\nrf.fit(X, y)\\ncross_val_score(rf, X, y, cv=10)\\n'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.datasets import make_classification\n",
    "#X, y = make_classification(n_samples=1000, n_features=31,\n",
    "#                           n_informative=2, n_redundant=0,\n",
    "#                           random_state=0, shuffle=False)\n",
    "rf = RandomForestClassifier(max_depth=10, n_estimators=40)\n",
    "rf.fit(X, y)\n",
    "cross_val_score(rf, X, y, cv=10)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf.predict([[1701824, 0.0, 0.0, 0.0, 0.0, 0.0,0.0, 0.0, 4545.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4545.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.ensemble import AdaBoostClassifier\\nfrom sklearn.datasets import make_classification\\n#X, y = make_classification(n_samples=1000, n_features=31,\\n#                            n_informative=2, n_redundant=0,\\n#                            random_state=10, shuffle=False)\\nada = AdaBoostClassifier(n_estimators=100, random_state=0)\\nada.fit(X, y)\\n#AdaBoostClassifier(n_estimators=100, random_state=10)\\n'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "#X, y = make_classification(n_samples=1000, n_features=31,\n",
    "#                            n_informative=2, n_redundant=0,\n",
    "#                            random_state=10, shuffle=False)\n",
    "ada = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "ada.fit(X, y)\n",
    "#AdaBoostClassifier(n_estimators=100, random_state=10)\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ada.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ada.predict([[1701194, 0.0, 0.0, 0.0, 0.0, 0.0,0.0, 0.0, 4545.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4545.9]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.neighbors import KNeighborsClassifier\\nneigh = KNeighborsClassifier(n_neighbors=2)\\nneigh.fit(X_train, y_train) \\nneigh.score(X_train,y_train)\\n'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=2)\n",
    "neigh.fit(X_train, y_train) \n",
    "neigh.score(X_train,y_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neigh.predict([[1710018,0,47683.0,0,9217.5,0,8420.0,0,0,8929.0,26208.6,0,6673.3,0,52351.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sklearn.metrics as metrics\n",
    "\n",
    "#prediction = neigh.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics.hamming_loss(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics.accuracy_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = neigh.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred=neigh.predict(X_test)\n",
    "#df2=pd.DataFrame(data=y_test, columns=['y_test'])\n",
    "#df2['y_pred']=y_pred\n",
    "#df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#LogisticRegression\\nfrom sklearn.linear_model import LogisticRegression\\nlr = LogisticRegression(solver='liblinear',multi_class='ovr' ,C=10)\\nlr.fit(X_train, y_train)\\nlr.score(X_test, y_test)\\n\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(solver='liblinear',multi_class='ovr' ,C=10)\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr.predict([[1710018,0,47683.0,0,9217.5,0,8420.0,0,0,8929.0,26208.6,0,6673.3,0,52351.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len([1710018,0,47683.0,0,9217.5,0,8420.0,0,0,8929.0,26208.6,0,6673.3,0,52351.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len([\"HEAT_ID\", 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 166, 180, 181, 182, 183, 190, 207, 208, 209, 210, 211, 212, 213, 214, 215, \"Sum\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f=len([1710018,0,47683.0,0,9217.5,0,8420.0,0,0,8929.0,26208.6,0,6673.3,0,52351.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0])\n",
    "#f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Random Forest\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\nrf = RandomForestClassifier(max_depth=10, n_estimators=40)\\nrf.fit(X_train, y_train)\\nrf.score(X_test, y_test)\\n'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=10, n_estimators=40)\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf.predict([[1710018,0,47683.0,0,9217.5,0,8420.0,0,0,8929.0,26208.6,0,6673.3,0,52351.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Decision tree\\nfrom sklearn import tree\\nDecTree = tree.DecisionTreeClassifier(max_depth=70, criterion='entropy',splitter='best')\\n\\nDecTree.fit(X_train,y_train)\\nDecTree.score(X_train,y_train)\\n\""
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Decision tree\n",
    "from sklearn import tree\n",
    "DecTree = tree.DecisionTreeClassifier(max_depth=70, criterion='entropy',splitter='best')\n",
    "\n",
    "DecTree.fit(X_train,y_train)\n",
    "DecTree.score(X_train,y_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DecTree.predict([[1710018,0,47683.0,0,9217.5,0,8420.0,0,0,8929.0,26208.6,0,6673.3,0,52351.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DecTree.predict([[1701194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4545.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4545.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ch=[1701194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4545.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4545.9]\n",
    "#len(ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### neural_network MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.neural_network import MLPClassifier\\nnralclf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)\\nnralclf.fit(X_train, y_train) \\nnralclf.score(X_train,y_train)\\n\""
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "nralclf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)\n",
    "nralclf.fit(X_train, y_train) \n",
    "nralclf.score(X_train,y_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nralclf.predict([[1710018,0,47683.0,0,9217.5,0,8420.0,0,0,8929.0,26208.6,0,6673.3,0,52351.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "#reg = LinearRegression()\n",
    "#reg.fit(X_train, y_train) \n",
    "#reg.score(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reg.predict([[1710018,0,47683.0,0,9217.5,0,8420.0,0,0,8929.0,26208.6,0,6673.3,0,52351.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "#from sklearn.svm import SVC\n",
    "#svm = SVC(gamma='auto')\n",
    "#svm.fit(X_train, y_train)\n",
    "#svm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm.predict([[1710018,0,47683.0,0,9217.5,0,8420.0,0,0,8929.0,26208.6,0,6673.3,0,52351.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I choosed Decission tree Coz It has better score from others:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#Model save in file to write mode\n",
    "#with open('finalized_model_neigh','wb') as f:\n",
    "#    pickle.dump(neigh,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Model Appro:1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating test harness , we will use 10-fold cross -validation into 10 parts crane on the 9 part estimate to \"accuracy\"\n",
    "split our data set into 10 part:train on the 9 part and test on the 1 part and this will be repeat for all combination of train and test pilots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#array=df.values # create a list of array with data\n",
    "#X=array[:,0:29] # all the column from 0-4\n",
    "#y=array[:,30] # the result/output cloumn 4\n",
    "#validation_size=0.20 #test data 0.2% from the data set\n",
    "#seed=6 #random number\n",
    "#X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X,y,test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed =6\n",
    "#scoring='accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spot Check Algorithms\n",
    "#models=[]\n",
    "#models.append(('LR',LogisticRegression()))\n",
    "#models.append(('LDA',LinearDiscriminantAnalysis()))\n",
    "#models.append(('KNN',KNeighborsClassifier()))\n",
    "#models.append(('CART',DecisionTreeClassifier()))\n",
    "#models.append(('NB',GaussianNB()))\n",
    "#models.append(('SVM',SVC()))\n",
    "#evalute each model in turn\n",
    "#results=[]\n",
    "#names=[]\n",
    "#for name,model in models:\n",
    "#    kfold=sklearn.model_selection.KFold(n_splits=10,random_state=seed)\n",
    "#    cv_results=sklearn.model_selection.cross_val_score(model,X_train,y_train,cv=kfold,scoring=scoring)\n",
    "#    results.append(cv_results)\n",
    "#    names.append(name)\n",
    "#    msg=\"%s: %f (%f)\" % (name,cv_results.mean(),cv_results.std())\n",
    "#    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C:\\Users\\rahim\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
    "  FutureWarning\n",
    "C:\\Users\\rahim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
    "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
    "\n",
    "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
    "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "Please also refer to the documentation for alternative solver options:\n",
    "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
    "C:\\Users\\rahim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
    "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
    "\n",
    "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
    "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "Please also refer to the documentation for alternative solver options:\n",
    "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
    "C:\\Users\\rahim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
    "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
    "\n",
    "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
    "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "Please also refer to the documentation for alternative solver options:\n",
    "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
    "C:\\Users\\rahim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
    "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
    "\n",
    "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
    "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "Please also refer to the documentation for alternative solver options:\n",
    "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
    "C:\\Users\\rahim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
    "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
    "\n",
    "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
    "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "Please also refer to the documentation for alternative solver options:\n",
    "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
    "C:\\Users\\rahim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
    "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
    "\n",
    "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
    "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "Please also refer to the documentation for alternative solver options:\n",
    "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
    "C:\\Users\\rahim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
    "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
    "\n",
    "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
    "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "Please also refer to the documentation for alternative solver options:\n",
    "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
    "C:\\Users\\rahim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
    "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
    "\n",
    "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
    "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "Please also refer to the documentation for alternative solver options:\n",
    "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
    "C:\\Users\\rahim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
    "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
    "\n",
    "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
    "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "Please also refer to the documentation for alternative solver options:\n",
    "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
    "C:\\Users\\rahim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
    "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
    "\n",
    "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
    "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "Please also refer to the documentation for alternative solver options:\n",
    "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
    "C:\\Users\\rahim\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
    "  FutureWarning\n",
    "Result:LR: 0.129470 (0.003673)\n",
    "Result: LDA: 0.106433 (0.004029)\n",
    "C:\\Users\\rahim\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
    "  FutureWarning\n",
    "Result: KNN: 0.010126 (0.000913)\n",
    "C:\\Users\\rahim\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
    "  FutureWarning\n",
    "Result: CART: 0.002114 (0.000815)\n",
    "C:\\Users\\rahim\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
    "  FutureWarning\n",
    "Result: NB: 0.002028 (0.003543)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2: Use K Fold Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually try suppling models with different parameters to cross_val_score function with 5 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbaseconda7cf0d73ef1fe4705970c7a1e7e51f1c2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
